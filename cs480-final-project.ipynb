{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fb082b",
   "metadata": {
    "papermill": {
     "duration": 0.007115,
     "end_time": "2023-04-17T15:38:36.401685",
     "exception": false,
     "start_time": "2023-04-17T15:38:36.394570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Instructions\n",
    "\n",
    "The following code is expected to be run in the Kaggle environment, with train.csv and test.csv located at '/kaggle/input/uw-cs480-winter23/', and the noisy images at '/kaggle/input/uw-cs480-winter23/noisy-images/noisy-images'. \n",
    "\n",
    "To run the code in the Kaggle environment, simply click \"Run All\". This will start the process of importing (and potentially downloading) all needed libraries/packages, data formatting/reading, the model initializations and training. During this process, there will be information produced in the logs for sample data as well as for the purpose of updating training progress. You can disregard these logs as they are solely informative.\n",
    "\n",
    "At the end, the code will then produce a 'submissions.csv' file, which contains the predictions made for the items in 'test.csv' in the format {'id', 'category'}. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb731e2",
   "metadata": {
    "papermill": {
     "duration": 0.006185,
     "end_time": "2023-04-17T15:38:36.414286",
     "exception": false,
     "start_time": "2023-04-17T15:38:36.408101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51bec19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:36.428985Z",
     "iopub.status.busy": "2023-04-17T15:38:36.428588Z",
     "iopub.status.idle": "2023-04-17T15:38:41.588578Z",
     "shell.execute_reply": "2023-04-17T15:38:41.587528Z"
    },
    "papermill": {
     "duration": 5.170849,
     "end_time": "2023-04-17T15:38:41.591717",
     "exception": false,
     "start_time": "2023-04-17T15:38:36.420868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage import io, transform\n",
    "import scipy.ndimage as ndi\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed296b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:41.607141Z",
     "iopub.status.busy": "2023-04-17T15:38:41.606695Z",
     "iopub.status.idle": "2023-04-17T15:38:41.724346Z",
     "shell.execute_reply": "2023-04-17T15:38:41.723086Z"
    },
    "papermill": {
     "duration": 0.128693,
     "end_time": "2023-04-17T15:38:41.727249",
     "exception": false,
     "start_time": "2023-04-17T15:38:41.598556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc14d9",
   "metadata": {
    "papermill": {
     "duration": 0.006187,
     "end_time": "2023-04-17T15:38:41.739785",
     "exception": false,
     "start_time": "2023-04-17T15:38:41.733598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476675ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:41.753657Z",
     "iopub.status.busy": "2023-04-17T15:38:41.753317Z",
     "iopub.status.idle": "2023-04-17T15:38:41.912597Z",
     "shell.execute_reply": "2023-04-17T15:38:41.911467Z"
    },
    "papermill": {
     "duration": 0.169672,
     "end_time": "2023-04-17T15:38:41.915821",
     "exception": false,
     "start_time": "2023-04-17T15:38:41.746149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/uw-cs480-winter23/'\n",
    "img_path = path + 'noisy-images/noisy-images/'\n",
    "\n",
    "# Dataframes\n",
    "train_df = pd.read_csv(path + 'train.csv')\n",
    "test_df = pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5953f7c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:41.931880Z",
     "iopub.status.busy": "2023-04-17T15:38:41.931518Z",
     "iopub.status.idle": "2023-04-17T15:38:42.005484Z",
     "shell.execute_reply": "2023-04-17T15:38:42.004352Z"
    },
    "papermill": {
     "duration": 0.085141,
     "end_time": "2023-04-17T15:38:42.007731",
     "exception": false,
     "start_time": "2023-04-17T15:38:41.922590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>gender</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>usage</th>\n",
       "      <th>noisyTextDescription</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51668</td>\n",
       "      <td>Sandal</td>\n",
       "      <td>Men</td>\n",
       "      <td>Tan</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Clarks Men ComfortSoft Wild Sweat Sandals</td>\n",
       "      <td>51668.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40012</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Men</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>John Players Flora Blue Jeans</td>\n",
       "      <td>40012.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56877</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Women</td>\n",
       "      <td>White</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Scullers For Mud Women White Trousers</td>\n",
       "      <td>56877.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42598</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Men</td>\n",
       "      <td>Black</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Puma Salvation Silly Enigma Black Sports Deerie</td>\n",
       "      <td>42598.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34629</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Women</td>\n",
       "      <td>Beige</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Arrow Woman Beige Top</td>\n",
       "      <td>34629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    category gender baseColour  season   usage  \\\n",
       "0  51668      Sandal    Men        Tan  Summer  Casual   \n",
       "1  40012  Bottomwear    Men       Blue  Summer  Casual   \n",
       "2  56877  Bottomwear  Women      White  Summer  Casual   \n",
       "3  42598       Shoes    Men      Black  Summer  Sports   \n",
       "4  34629     Topwear  Women      Beige  Summer  Casual   \n",
       "\n",
       "                              noisyTextDescription   img_path  \n",
       "0        Clarks Men ComfortSoft Wild Sweat Sandals  51668.jpg  \n",
       "1                    John Players Flora Blue Jeans  40012.jpg  \n",
       "2            Scullers For Mud Women White Trousers  56877.jpg  \n",
       "3  Puma Salvation Silly Enigma Black Sports Deerie  42598.jpg  \n",
       "4                            Arrow Woman Beige Top  34629.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get image file name\n",
    "train_df['img_path'] = train_df['id'].astype(str) + '.jpg'\n",
    "test_df['img_path'] = test_df['id'].astype(str) + '.jpg'\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db450bdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:42.023364Z",
     "iopub.status.busy": "2023-04-17T15:38:42.022397Z",
     "iopub.status.idle": "2023-04-17T15:38:42.089236Z",
     "shell.execute_reply": "2023-04-17T15:38:42.088319Z"
    },
    "papermill": {
     "duration": 0.076535,
     "end_time": "2023-04-17T15:38:42.091296",
     "exception": false,
     "start_time": "2023-04-17T15:38:42.014761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>gender</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>usage</th>\n",
       "      <th>noisyTextDescription</th>\n",
       "      <th>img_path</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>colour_encoded</th>\n",
       "      <th>season_encoded</th>\n",
       "      <th>usage_encoded</th>\n",
       "      <th>category_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51668</td>\n",
       "      <td>Sandal</td>\n",
       "      <td>Men</td>\n",
       "      <td>Tan</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Clarks Men ComfortSoft Wild Sweat Sandals</td>\n",
       "      <td>51668.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40012</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Men</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>John Players Flora Blue Jeans</td>\n",
       "      <td>40012.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56877</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Women</td>\n",
       "      <td>White</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Scullers For Mud Women White Trousers</td>\n",
       "      <td>56877.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42598</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Men</td>\n",
       "      <td>Black</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Puma Salvation Silly Enigma Black Sports Deerie</td>\n",
       "      <td>42598.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34629</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Women</td>\n",
       "      <td>Beige</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Arrow Woman Beige Top</td>\n",
       "      <td>34629.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    category gender baseColour  season   usage  \\\n",
       "0  51668      Sandal    Men        Tan  Summer  Casual   \n",
       "1  40012  Bottomwear    Men       Blue  Summer  Casual   \n",
       "2  56877  Bottomwear  Women      White  Summer  Casual   \n",
       "3  42598       Shoes    Men      Black  Summer  Sports   \n",
       "4  34629     Topwear  Women      Beige  Summer  Casual   \n",
       "\n",
       "                              noisyTextDescription   img_path  gender_encoded  \\\n",
       "0        Clarks Men ComfortSoft Wild Sweat Sandals  51668.jpg               2   \n",
       "1                    John Players Flora Blue Jeans  40012.jpg               2   \n",
       "2            Scullers For Mud Women White Trousers  56877.jpg               4   \n",
       "3  Puma Salvation Silly Enigma Black Sports Deerie  42598.jpg               2   \n",
       "4                            Arrow Woman Beige Top  34629.jpg               4   \n",
       "\n",
       "   colour_encoded  season_encoded  usage_encoded  category_encoded  \n",
       "0              40               2              0                18  \n",
       "1               2               2              0                 4  \n",
       "2              44               2              0                 4  \n",
       "3               1               2              5                21  \n",
       "4               0               2              0                24  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode gender, baseColour, season, usage, and category\n",
    "#    and keep map for each: {encoded_label: actual_label}\n",
    "le = LabelEncoder()\n",
    "gender_encoded = le.fit_transform(train_df['gender'])\n",
    "train_df['gender_encoded'] = gender_encoded\n",
    "gender_map = {i: l for i, l in enumerate(le.classes_)}\n",
    "gender_encoded = le.fit_transform(test_df['gender'])\n",
    "test_df['gender_encoded'] = gender_encoded\n",
    "\n",
    "colour_encoded = le.fit_transform(train_df['baseColour'])\n",
    "train_df['colour_encoded'] = colour_encoded\n",
    "colour_map = {i: l for i, l in enumerate(le.classes_)}\n",
    "colour_encoded = le.fit_transform(test_df['baseColour'])\n",
    "test_df['colour_encoded'] = colour_encoded\n",
    "\n",
    "season_encoded = le.fit_transform(train_df['season'])\n",
    "train_df['season_encoded'] = season_encoded\n",
    "season_map = {i: l for i, l in enumerate(le.classes_)}\n",
    "season_encoded = le.fit_transform(test_df['season'])\n",
    "test_df['season_encoded'] = season_encoded\n",
    "\n",
    "usage_encoded = le.fit_transform(train_df['usage'])\n",
    "train_df['usage_encoded'] = usage_encoded\n",
    "usage_map = {i: l for i, l in enumerate(le.classes_)} \n",
    "usage_encoded = le.fit_transform(test_df['usage'])\n",
    "test_df['usage_encoded'] = usage_encoded\n",
    "\n",
    "category_encoded = le.fit_transform(train_df['category'])\n",
    "train_df['category_encoded'] = category_encoded\n",
    "category_map = {i: l for i, l in enumerate(le.classes_)}\n",
    "\n",
    "train_df.head()\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9261c2fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:42.106240Z",
     "iopub.status.busy": "2023-04-17T15:38:42.105938Z",
     "iopub.status.idle": "2023-04-17T15:38:42.115894Z",
     "shell.execute_reply": "2023-04-17T15:38:42.114188Z"
    },
    "papermill": {
     "duration": 0.019864,
     "end_time": "2023-04-17T15:38:42.118183",
     "exception": false,
     "start_time": "2023-04-17T15:38:42.098319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom Dataset to read in dataset\n",
    "class EcommerceDataset(Dataset):\n",
    "    def __init__(self, data_frame, root_dir, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # catgorical data\n",
    "        data = self.data_frame.loc[idx, 'gender_encoded':'usage_encoded'].values.astype('int64')\n",
    "        data=torch.from_numpy(data)\n",
    "        \n",
    "        # image\n",
    "        img_path = os.path.join(self.root_dir, self.data_frame.loc[idx, 'img_path'])\n",
    "        image = Image.open(img_path)\n",
    "        image = (np.array(image))\n",
    "        r = image[:,:,0].flatten()\n",
    "        g = image[:,:,1].flatten()\n",
    "        b = image[:,:,2].flatten()\n",
    "        image = ndi.gaussian_filter(image, sigma=1.25)  # gaussian filter to reduce noise\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # text\n",
    "        text = self.data_frame.loc[idx, 'noisyTextDescription']\n",
    "        \n",
    "        # label\n",
    "        category = self.data_frame.iloc[idx, -1]\n",
    "    \n",
    "        return data, image, text, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8aa8487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:42.134375Z",
     "iopub.status.busy": "2023-04-17T15:38:42.132650Z",
     "iopub.status.idle": "2023-04-17T15:38:42.140395Z",
     "shell.execute_reply": "2023-04-17T15:38:42.139497Z"
    },
    "papermill": {
     "duration": 0.017352,
     "end_time": "2023-04-17T15:38:42.142476",
     "exception": false,
     "start_time": "2023-04-17T15:38:42.125124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4, 0.4, 0.4), (0.4, 0.4, 0.4))])\n",
    "\n",
    "# Training set\n",
    "train_set = EcommerceDataset(\n",
    "    data_frame=train_df,\n",
    "    root_dir=img_path,\n",
    "    transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=64)\n",
    "\n",
    "# Test set\n",
    "test_set = EcommerceDataset(\n",
    "    data_frame=test_df,\n",
    "    root_dir=img_path,\n",
    "    transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be48bfd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:42.157361Z",
     "iopub.status.busy": "2023-04-17T15:38:42.157088Z",
     "iopub.status.idle": "2023-04-17T15:38:42.677650Z",
     "shell.execute_reply": "2023-04-17T15:38:42.676625Z"
    },
    "papermill": {
     "duration": 0.530404,
     "end_time": "2023-04-17T15:38:42.679840",
     "exception": false,
     "start_time": "2023-04-17T15:38:42.149436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United flops of Benetton Men Solid Grey Trousers\n",
      "0\n",
      "tensor([ 2, 13,  0,  0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample iteration\n",
    "data, images, texts, labels = next(iter(test_loader))\n",
    "plt.imshow(images[0].numpy().transpose((1,2,0)))\n",
    "img = images[0]\n",
    "print(texts[0])\n",
    "print(labels[0].item())\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85753a4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-10T17:34:23.604652Z",
     "iopub.status.idle": "2023-04-10T17:34:23.606207Z",
     "shell.execute_reply": "2023-04-10T17:34:23.605851Z",
     "shell.execute_reply.started": "2023-04-10T17:34:23.605807Z"
    },
    "papermill": {
     "duration": 0.006929,
     "end_time": "2023-04-17T15:38:42.694352",
     "exception": false,
     "start_time": "2023-04-17T15:38:42.687423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d30d3558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:42.711244Z",
     "iopub.status.busy": "2023-04-17T15:38:42.709445Z",
     "iopub.status.idle": "2023-04-17T15:38:46.195175Z",
     "shell.execute_reply": "2023-04-17T15:38:46.194111Z"
    },
    "papermill": {
     "duration": 3.496508,
     "end_time": "2023-04-17T15:38:46.197686",
     "exception": false,
     "start_time": "2023-04-17T15:38:42.701178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CNN for image\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(13056,3256)\n",
    "        self.fc2 = nn.Linear(3256,512)\n",
    "        self.fc3 = nn.Linear(512, 27)\n",
    "\n",
    "        # define proportion of neurons to dropout\n",
    "        self.pool_dropout = nn.Dropout(0.25)\n",
    "        self.layer_dropout = nn.Dropout(0.25)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.pool_dropout(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.pool_dropout(x)\n",
    "\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.layer_dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.layer_dropout(x)\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "CNN_model = CNN().to(device)\n",
    "CNN_optimizer = torch.optim.Adam(CNN_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23128e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:46.215146Z",
     "iopub.status.busy": "2023-04-17T15:38:46.214036Z",
     "iopub.status.idle": "2023-04-17T15:38:46.224692Z",
     "shell.execute_reply": "2023-04-17T15:38:46.223580Z"
    },
    "papermill": {
     "duration": 0.021887,
     "end_time": "2023-04-17T15:38:46.227269",
     "exception": false,
     "start_time": "2023-04-17T15:38:46.205382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DNN for categorical data\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 27)\n",
    "        \n",
    "        # define proportion of neurons to dropout\n",
    "        self.layer_dropout = nn.Dropout(0.25)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.layer_dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.layer_dropout(x)\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "DNN_model = DNN().to(device)\n",
    "DNN_optimizer = torch.optim.Adam(DNN_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb77b1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:46.243014Z",
     "iopub.status.busy": "2023-04-17T15:38:46.242718Z",
     "iopub.status.idle": "2023-04-17T15:38:46.255879Z",
     "shell.execute_reply": "2023-04-17T15:38:46.254824Z"
    },
    "papermill": {
     "duration": 0.023542,
     "end_time": "2023-04-17T15:38:46.258325",
     "exception": false,
     "start_time": "2023-04-17T15:38:46.234783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions for text classification\n",
    "# Code snippet based on tutorial from PyTorch\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for data, image, text, category in data_iter:\n",
    "        keywords = []\n",
    "        for t in text:\n",
    "            t = regex.sub('', t)   # remove non alphabet chars\n",
    "            t = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", t) # add space before capital letters\n",
    "            t = ' '.join( [w for w in t.split() if len(w)>1] )   # remove single chars\n",
    "\n",
    "            tokens = word_tokenize(t)\n",
    "            tagged_tokens = nltk.pos_tag(tokens)\n",
    "\n",
    "            # Iterate over the tagged tokens and extract keywords\n",
    "            for token, tag in tagged_tokens:\n",
    "                if tag.startswith('NN'):\n",
    "                    # If the tag starts with NN (noun) add to list of keywords\n",
    "                    keywords.append(token.lower())\n",
    "        final_string = \" \".join(keywords)\n",
    "        yield tokenizer(final_string)\n",
    "\n",
    "def process_text(text):\n",
    "    text_list, offsets = [], [0]\n",
    "    for t in text: \n",
    "        t = regex.sub('', t)   # remove non alphabet chars\n",
    "        t = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", t) # add space before capital letters\n",
    "        t = ' '.join( [w for w in t.split() if len(w)>1] )   # remove single chars\n",
    "        \n",
    "        tokens = word_tokenize(t)\n",
    "        tagged_tokens = nltk.pos_tag(tokens)\n",
    "        keywords = []\n",
    "        for token, tag in tagged_tokens:\n",
    "                if tag.startswith('NN'):\n",
    "                    # If the tag starts with NN (noun) add to list of keywords\n",
    "                    keywords.append(token.lower())\n",
    "        t = \" \".join(keywords)\n",
    "        processed_text = torch.tensor(text_pipeline(t), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17068137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:38:46.274017Z",
     "iopub.status.busy": "2023-04-17T15:38:46.273169Z",
     "iopub.status.idle": "2023-04-17T15:41:40.184971Z",
     "shell.execute_reply": "2023-04-17T15:41:40.183763Z"
    },
    "papermill": {
     "duration": 173.922503,
     "end_time": "2023-04-17T15:41:40.188036",
     "exception": false,
     "start_time": "2023-04-17T15:38:46.265533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build vocab\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_loader), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "899c1d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:41:40.205120Z",
     "iopub.status.busy": "2023-04-17T15:41:40.204134Z",
     "iopub.status.idle": "2023-04-17T15:41:40.220730Z",
     "shell.execute_reply": "2023-04-17T15:41:40.219779Z"
    },
    "papermill": {
     "duration": 0.026845,
     "end_time": "2023-04-17T15:41:40.222790",
     "exception": false,
     "start_time": "2023-04-17T15:41:40.195945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model for text\n",
    "# Code snippets based on tutorial from PyTorch\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(len(vocab), 64, sparse=False)\n",
    "        self.fc = nn.Linear(64, 27)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "text_model = TextModel().to(device)\n",
    "text_optimizer = torch.optim.Adam(text_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e67bef",
   "metadata": {
    "papermill": {
     "duration": 0.006807,
     "end_time": "2023-04-17T15:41:40.236817",
     "exception": false,
     "start_time": "2023-04-17T15:41:40.230010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train and Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e3daf24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:41:40.252679Z",
     "iopub.status.busy": "2023-04-17T15:41:40.252385Z",
     "iopub.status.idle": "2023-04-17T15:41:40.257135Z",
     "shell.execute_reply": "2023-04-17T15:41:40.255842Z"
    },
    "papermill": {
     "duration": 0.015722,
     "end_time": "2023-04-17T15:41:40.259709",
     "exception": false,
     "start_time": "2023-04-17T15:41:40.243987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "679d4032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:41:40.274947Z",
     "iopub.status.busy": "2023-04-17T15:41:40.274679Z",
     "iopub.status.idle": "2023-04-17T15:41:40.285583Z",
     "shell.execute_reply": "2023-04-17T15:41:40.284256Z"
    },
    "papermill": {
     "duration": 0.020834,
     "end_time": "2023-04-17T15:41:40.287632",
     "exception": false,
     "start_time": "2023-04-17T15:41:40.266798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train function\n",
    "def train(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, correct = 0, 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (categorical_data, images, text, categories) in enumerate(dataloader):\n",
    "        categorical_data, images, text, categories = categorical_data.to(device), images.to(device), text, categories.to(device)\n",
    "        \n",
    "        # CNN \n",
    "        if (type(model).__name__ == 'CNN'):\n",
    "            CNN_optimizer.zero_grad()\n",
    "            pred = CNN_model(images)\n",
    "            loss = loss_fn(pred, categories)\n",
    "            loss.backward()\n",
    "            CNN_optimizer.step()\n",
    "            _, pred = torch.max(pred, 1)\n",
    "        \n",
    "        # DNN prediction\n",
    "        elif (type(model).__name__ == 'DNN'):\n",
    "            DNN_optimizer.zero_grad()\n",
    "            pred = DNN_model(categorical_data.float())\n",
    "            loss = loss_fn(pred, categories)\n",
    "            loss.backward()\n",
    "            DNN_optimizer.step()\n",
    "            _, pred = torch.max(pred, 1)\n",
    "        \n",
    "        # Text\n",
    "        else:\n",
    "            text_optimizer.zero_grad()\n",
    "            text, offsets = process_text(text)\n",
    "            pred = text_model(text, offsets)\n",
    "            loss = loss_fn(pred, categories)\n",
    "            loss.backward()\n",
    "            text_optimizer.step()\n",
    "            _, pred = torch.max(pred, 1)\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "        correct += sum(x == y for x, y in zip(pred, categories))\n",
    "\n",
    "    average_train_loss = train_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    return accuracy, average_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "522d48d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:41:40.302739Z",
     "iopub.status.busy": "2023-04-17T15:41:40.302472Z",
     "iopub.status.idle": "2023-04-17T15:41:40.308542Z",
     "shell.execute_reply": "2023-04-17T15:41:40.307470Z"
    },
    "papermill": {
     "duration": 0.016282,
     "end_time": "2023-04-17T15:41:40.310872",
     "exception": false,
     "start_time": "2023-04-17T15:41:40.294590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# voting\n",
    "def vote(image_pred, category_pred, text_pred):\n",
    "    predictions = []\n",
    "    for (i, c, t) in zip(image_pred, category_pred, text_pred):\n",
    "        votes = set()\n",
    "        for vote in [i, c, t]:\n",
    "            if vote in votes:\n",
    "                predictions.append(vote)\n",
    "                break\n",
    "            votes.add(vote.item())\n",
    "        predictions.append(t.item())        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07a0757c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:41:40.326180Z",
     "iopub.status.busy": "2023-04-17T15:41:40.325895Z",
     "iopub.status.idle": "2023-04-17T15:41:40.335586Z",
     "shell.execute_reply": "2023-04-17T15:41:40.334523Z"
    },
    "papermill": {
     "duration": 0.020378,
     "end_time": "2023-04-17T15:41:40.337992",
     "exception": false,
     "start_time": "2023-04-17T15:41:40.317614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(dataloader, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    CNN_model.eval()\n",
    "    DNN_model.eval()\n",
    "    text_model.eval()\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, (categorical_data, images, text, categories) in enumerate(dataloader):\n",
    "                categorical_data, images, text, categories = categorical_data.to(device), images.to(device), text, categories.to(device)\n",
    "\n",
    "                image_pred = CNN_model(images)\n",
    "                _, image_pred = torch.max(image_pred, 1)\n",
    "\n",
    "                category_pred = DNN_model(categorical_data.float())\n",
    "                _, category_pred = torch.max(category_pred, 1)\n",
    "\n",
    "                text, offsets = process_text(text)\n",
    "                text_pred = text_model(text, offsets)\n",
    "                _, text_pred = torch.max(text_pred, 1)\n",
    "\n",
    "                final_pred = vote(image_pred, category_pred, text_pred)\n",
    "                \n",
    "                test_loss += loss_fn(torch.Tensor(final_pred).to(device), categories.float().to(device)).item()\n",
    "                correct += sum(x == y for x, y in zip(final_pred, categories))\n",
    "                \n",
    "    average_test_loss = test_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    return accuracy, average_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0587ed88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:41:40.353927Z",
     "iopub.status.busy": "2023-04-17T15:41:40.353095Z",
     "iopub.status.idle": "2023-04-17T15:41:40.361092Z",
     "shell.execute_reply": "2023-04-17T15:41:40.360041Z"
    },
    "papermill": {
     "duration": 0.018083,
     "end_time": "2023-04-17T15:41:40.363378",
     "exception": false,
     "start_time": "2023-04-17T15:41:40.345295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def train_all(epochs=7):\n",
    "  for t in tqdm(range(epochs)):\n",
    "      print(f\"Epoch {t+1}:\")\n",
    "    \n",
    "      # produce training set and validation set\n",
    "      train_size = int(len(train_set) * 0.9)\n",
    "      test_size = int(len(train_set) - train_size)\n",
    "      split_train, split_valid = random_split(train_set, [train_size, test_size])\n",
    "      train_loader = DataLoader(split_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "      valid_loader = DataLoader(split_valid, batch_size=BATCH_SIZE, shuffle=True)\n",
    "      \n",
    "      # train\n",
    "      text_train_accuracy, text_average_train_loss = train(train_loader, text_model, loss_fn)\n",
    "      CNN_train_accuracy, CNN_average_train_loss = train(train_loader, CNN_model, loss_fn)\n",
    "      DNN_train_accuracy, DNN_average_train_loss = train(train_loader, DNN_model, loss_fn)\n",
    "      print(f\"\\tAverage train accuracy: {100*CNN_train_accuracy:0.2f}% {100*DNN_train_accuracy:0.2f}% {100*text_train_accuracy:0.2f}%\\t Avg train loss: {CNN_average_train_loss:>4f} {DNN_average_train_loss:>4f} {text_average_train_loss:>4f}\\t\")\n",
    "    \n",
    "      # test\n",
    "      test_accuracy, test_loss = test(valid_loader, loss_fn)\n",
    "      print(f\"\\tTest accuracy: {100*test_accuracy:0.2f}% \\t Test loss: {test_loss:>4f}\")\n",
    "\n",
    "  return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99506101",
   "metadata": {
    "papermill": {
     "duration": 0.00674,
     "end_time": "2023-04-17T15:41:40.377049",
     "exception": false,
     "start_time": "2023-04-17T15:41:40.370309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88bbbdaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T15:41:40.392924Z",
     "iopub.status.busy": "2023-04-17T15:41:40.392229Z",
     "iopub.status.idle": "2023-04-17T16:02:45.590187Z",
     "shell.execute_reply": "2023-04-17T16:02:45.589102Z"
    },
    "papermill": {
     "duration": 1265.208351,
     "end_time": "2023-04-17T16:02:45.592533",
     "exception": false,
     "start_time": "2023-04-17T15:41:40.384182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tAverage train accuracy: 55.59% 33.74% 42.82%\t Avg train loss: 1.754116 2.531840 2.379717\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [03:08<18:51, 188.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest accuracy: 53.86% \t Test loss: 6149.220402\n",
      "Epoch 2:\n",
      "\tAverage train accuracy: 73.07% 36.65% 63.77%\t Avg train loss: 1.167750 2.311568 1.507050\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [06:07<15:14, 182.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest accuracy: 71.15% \t Test loss: 7188.354392\n",
      "Epoch 3:\n",
      "\tAverage train accuracy: 76.12% 38.68% 74.43%\t Avg train loss: 1.055784 2.200405 1.163259\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [09:07<12:05, 181.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest accuracy: 76.19% \t Test loss: 7418.795956\n",
      "Epoch 4:\n",
      "\tAverage train accuracy: 77.75% 39.16% 78.65%\t Avg train loss: 1.000922 2.138766 0.988141\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [12:06<09:01, 180.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest accuracy: 78.46% \t Test loss: 7475.232235\n",
      "Epoch 5:\n",
      "\tAverage train accuracy: 79.07% 40.26% 80.80%\t Avg train loss: 0.937881 2.064839 0.894594\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [15:04<05:59, 179.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest accuracy: 81.14% \t Test loss: 7718.533936\n",
      "Epoch 6:\n",
      "\tAverage train accuracy: 79.86% 41.29% 82.07%\t Avg train loss: 0.899268 2.013670 0.826320\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [18:04<02:59, 179.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest accuracy: 83.13% \t Test loss: 7655.239488\n",
      "Epoch 7:\n",
      "\tAverage train accuracy: 80.67% 42.03% 83.55%\t Avg train loss: 0.853877 1.966326 0.758858\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [21:05<00:00, 180.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest accuracy: 82.02% \t Test loss: 7612.355368\n",
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training started')\n",
    "train_all()\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4d2ea60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T16:02:45.617968Z",
     "iopub.status.busy": "2023-04-17T16:02:45.617024Z",
     "iopub.status.idle": "2023-04-17T16:02:45.628927Z",
     "shell.execute_reply": "2023-04-17T16:02:45.627899Z"
    },
    "papermill": {
     "duration": 0.030652,
     "end_time": "2023-04-17T16:02:45.631789",
     "exception": false,
     "start_time": "2023-04-17T16:02:45.601137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# produce training set and validation set\n",
    "train_size = int(len(train_set) * 0.9)\n",
    "test_size = int(len(train_set) - train_size)\n",
    "split_train, split_valid = random_split(train_set, [train_size, test_size])\n",
    "train_loader = DataLoader(split_train, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(split_valid, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f94b1124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T16:02:45.668679Z",
     "iopub.status.busy": "2023-04-17T16:02:45.668331Z",
     "iopub.status.idle": "2023-04-17T16:02:46.160648Z",
     "shell.execute_reply": "2023-04-17T16:02:46.159338Z"
    },
    "papermill": {
     "duration": 0.517309,
     "end_time": "2023-04-17T16:02:46.163609",
     "exception": false,
     "start_time": "2023-04-17T16:02:45.646300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(CNN_model, 'CNN_model.pt')\n",
    "torch.save(DNN_model, 'DNN_model.pt')\n",
    "torch.save(text_model, 'text_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e22732",
   "metadata": {
    "papermill": {
     "duration": 0.012379,
     "end_time": "2023-04-17T16:02:46.189833",
     "exception": false,
     "start_time": "2023-04-17T16:02:46.177454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make predictions for test and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc386d42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T16:02:46.216575Z",
     "iopub.status.busy": "2023-04-17T16:02:46.216123Z",
     "iopub.status.idle": "2023-04-17T16:02:46.398276Z",
     "shell.execute_reply": "2023-04-17T16:02:46.397236Z"
    },
    "papermill": {
     "duration": 0.199048,
     "end_time": "2023-04-17T16:02:46.401588",
     "exception": false,
     "start_time": "2023-04-17T16:02:46.202540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CNN_model = torch.load('CNN_model.pt')\n",
    "DNN_model = torch.load('DNN_model.pt')\n",
    "text_model = torch.load('text_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72dcc23a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T16:02:46.429805Z",
     "iopub.status.busy": "2023-04-17T16:02:46.429461Z",
     "iopub.status.idle": "2023-04-17T16:02:46.441951Z",
     "shell.execute_reply": "2023-04-17T16:02:46.441091Z"
    },
    "papermill": {
     "duration": 0.029313,
     "end_time": "2023-04-17T16:02:46.444531",
     "exception": false,
     "start_time": "2023-04-17T16:02:46.415218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "def predict(dataloader, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    CNN_model.eval()\n",
    "    DNN_model.eval()\n",
    "    text_model.eval()\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, (categorical_data, images, text, categories) in enumerate(dataloader):\n",
    "            categorical_data, images, text, categories = categorical_data.to(device), images.to(device), text, categories.to(device)\n",
    "            \n",
    "            image_pred = CNN_model(images)\n",
    "            _, image_pred = torch.max(image_pred, 1)\n",
    "            \n",
    "            category_pred = DNN_model(categorical_data.float())\n",
    "            _, category_pred = torch.max(category_pred, 1)\n",
    "            \n",
    "            text, offsets = process_text(text)\n",
    "            text_pred = text_model(text, offsets)\n",
    "            _, text_pred = torch.max(text_pred, 1)\n",
    "            \n",
    "            final_pred = vote(image_pred, category_pred, text_pred)\n",
    "            \n",
    "            outputs.append(final_pred[0])\n",
    "    \n",
    "    return torch.Tensor(outputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6092265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T16:02:46.471904Z",
     "iopub.status.busy": "2023-04-17T16:02:46.471577Z",
     "iopub.status.idle": "2023-04-17T16:06:28.296003Z",
     "shell.execute_reply": "2023-04-17T16:06:28.294886Z"
    },
    "papermill": {
     "duration": 221.841291,
     "end_time": "2023-04-17T16:06:28.298780",
     "exception": false,
     "start_time": "2023-04-17T16:02:46.457489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = predict(test_loader, loss_fn)\n",
    "\n",
    "processed_predictions = predictions.cpu().numpy().astype(int)\n",
    "mapped_predictions = [category_map[y] for y in processed_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bb63bee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T16:06:28.317994Z",
     "iopub.status.busy": "2023-04-17T16:06:28.317658Z",
     "iopub.status.idle": "2023-04-17T16:06:28.348185Z",
     "shell.execute_reply": "2023-04-17T16:06:28.347140Z"
    },
    "papermill": {
     "duration": 0.042829,
     "end_time": "2023-04-17T16:06:28.350528",
     "exception": false,
     "start_time": "2023-04-17T16:06:28.307699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_df.id, 'category': mapped_predictions})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1684.747887,
   "end_time": "2023-04-17T16:06:31.254722",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-17T15:38:26.506835",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
